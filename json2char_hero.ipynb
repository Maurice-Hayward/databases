{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import csv\n",
    "import string\n",
    "import requests\n",
    "import re\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_file = open('newCharacterList.csv', \"r\", errors='replace')\n",
    "char_file.readline()\n",
    "char_id = []\n",
    "for line in  char_file:\n",
    "    char_id.append( line.split(',')[0])\n",
    "char_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'char_ hero_villian.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_put = open(filepath, \"w+\", newline='')\n",
    "datafile = csv.writer(out_put)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files =  glob.glob('./char_json/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./char_json/char100.json\n",
      "wiki\n",
      "http://marvel.com/universe/Abomination?utm_campaign=apiRef&utm_source=a6d013486e4b973db952de93bbd7e9e1\n"
     ]
    }
   ],
   "source": [
    "with open(files[1]) as data_file:\n",
    "    print(files[1])\n",
    "    js = json.load(data_file)\n",
    "    r = requests.get(js['data']['results'][4]['urls'][1]['url'])\n",
    "    print(js['data']['results'][4]['urls'][1]['type'])\n",
    "    print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " p = soup.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont = []\n",
    "for i in p:\n",
    "    match = re.search('Category', str(i))\n",
    "    if match:\n",
    "        cont.append(i.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Avengers'] in cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "header = ['char_id', 'status', 'sex']\n",
    "datafile.writerow(header)\n",
    "i = 0\n",
    "for fn in files:\n",
    "    with open(fn) as data_file:\n",
    "        for char in json.load(data_file)['data']['results']:\n",
    "            if str(char['id']) in char_id:\n",
    "                row = []\n",
    "                cont = []\n",
    "                for urll in char['urls']:\n",
    "                    if urll['type'] == 'wiki':\n",
    "                        r = requests.get(urll['url'])\n",
    "                        soup = BeautifulSoup(r.content)\n",
    "                        p = soup.findAll('a')\n",
    "                        for a in p:\n",
    "                            match = re.search('Category', str(a))\n",
    "                            if match:\n",
    "                                cont.append(a.contents)\n",
    "                \n",
    "                row.append(str(char['id']))\n",
    "                if ['Heroes'] in cont:\n",
    "                    row.append('Heroes')\n",
    "                elif ['Villains'] in cont:\n",
    "                    row.append('Villains')\n",
    "                else:\n",
    "                    row.append('Neutral')\n",
    "                \n",
    "                if ['Women'] in cont:\n",
    "                    row.append('Woman')\n",
    "                else:\n",
    "                    row.append('Man')\n",
    "                \n",
    "                datafile.writerow(row)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "out_put.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_put.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
